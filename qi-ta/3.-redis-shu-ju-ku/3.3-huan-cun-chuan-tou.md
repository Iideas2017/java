# 3.3 缓存穿透、雪崩

## 1. 缓存穿透

### 1.1 什么是缓存穿透？

       所谓的缓存穿透，简单来讲就是查询某些不存在的key时，**缓存和数据库查询结果**都为空，而空的结果又不被缓存起来，而导致每次查询都去请求数据库层的情况。

     **缓存不命中**，进而导致**每次查询都去查询数据库**，缓存也就失去了作用，通常表现为服务器负载迅速上升，严重时可能直接宕机。

![](../../.gitbook/assets/image%20%28316%29.png)

### 1.2 如何避免？

 缓存空数据和使用布隆过滤器

#### 1. 缓存空数据

当第一次查询数据库时，若数据不存在，返回空数据时将其写入缓存，后续查询就不必再去查询数据库了。

![](../../.gitbook/assets/image%20%28179%29.png)

     存在问题：如果key过期时间较长，出现恶意攻击时，容易出现**内存不够**的情况。另外，需要额外的业务逻辑处理数据库与缓存中数据一致性的问题。

#### 2. 布隆过滤器拦截

访问缓存之前，先从布隆过滤器中验证数据是否存在。

![](../../.gitbook/assets/image%20%28359%29.png)

简单来讲就是使用**多个hash函数**将**一个key映射到一个很长的二进制向量的多个比特位中**，类似于**hash set**。

存在问题：维护复杂，建议只在海量数据的情况下使用。

## 2. 缓存雪崩

### 2.1 什么是缓存雪崩？

       缓存雪崩就是**指缓存由于某些原因（比如 宕机、cache服务挂了或者不响应）整体crash掉了，导致大量请求到达后端数据库，从而导致数据库崩溃，整个系统崩溃，发生灾难。**

 如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。

### 2.2 如何避免？

1：在缓存失效后，通过**加锁或者队列**来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。

2：不同的key，设置不同的过期时间，让**缓存失效的时间点尽量均匀**。

3：做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期

#### **1）事前解决方案**

* 保证缓存层服务高可用性

和飞机都有多个引擎一样，如果缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务，例如 Redis Sentinel 和 Redis Cluster 都实现了高可用。

**部署方式一**：双机房部署，一套Redis Cluster，部分机器在一个机房，另一部分机器在另外一个机房。

**部署方式二**：双机房部署，两套Redis Cluster，两套Redis Cluster之间做一个数据同步。

#### **2）事中解决方案：**

* 对缓存访问进行 **资源隔离（熔断）**、**Fail Silent 降级**

避免所有资源hang在访问缓存上，当判断缓存出现问题，则自动进行熔断并按预设进行降级操作。

* ehcache本地缓存

应对零散的缓存中数据被清除掉的现象，另外一个主要预防缓存彻底崩溃，ehcache的缓存还能支撑一阵。

* 对源服务访问进行 限流、资源隔离（熔断）、Stubbed 降级。

无论是缓存层还是存储层都会有出错的概率，可以将它们视同为资源。作为并发量较大的系统，假如有一个资源不可用，可能会造成线程全部 hang 在这个资源上，造成整个系统不可用。相信大家一定遇到过这样的页面：这些应该就是淘宝的降级策略。

![](../../.gitbook/assets/image%20%28329%29.png)

 降级在高并发系统中是非常正常的：比如推荐服务中，如果个性化推荐服务不可用，可以降级补充热点数据，不至于造成前端页面是开天窗。

#### **3\)事后解决方案**

* Redis数据备份和恢复
* 快速缓存预热

## 3. 热点key

        我们通常使用 **缓存 + 过期时间**的策略来帮助我们加速接口的访问速度，减少了后端负载，同时保证功能的更新，一般情况下这种模式已经基本满足要求了。

       但是有**两个问题**如果同时出现，可能就会对系统造成致命的危害：

      \(1\) 这个key是**一个热点key**（例如一个重要的新闻，一个热门的八卦新闻等等），所以这种key访问量可能非常大。

      \(2\) 缓存的**构建是需要一定时间**的。（可能是一个复杂计算，例如复杂的sql、多次IO、多个依赖\(各种接口\)等等）

       于是就会出现一个致命问题：**在缓存失效的瞬间，有大量线程来构建缓存**（见下图），造成后端负载加大，甚至可能会让系统崩溃 。

    解决方法：

1. 使用**互斥锁\(mutex key\)**:这种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了  


2. **"提前"使用互斥锁\(mutex key\)**：在value内部设置1个超时值\(timeout1\), timeout1比实际的memcache timeout\(timeout2\)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。  


3. **"永远不过期"**：

 这里的“永远不过期”包含两层意思：

    \(1\) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。

    \(2\) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

4. 资源保护：可以**做资源的隔离保护主线程池**，如果把这个应用到缓存的构建也未尝不可。

四种方案对比：

      作为一个并发量较大的互联网应用，我们的目标有3个:

      1. 加快用户访问速度，提高用户体验。

      2. 降低后端负载，保证系统平稳。

      3. 保证数据“尽可能”及时更新\(要不要完全一致，取决于业务，而不是技术。\)

      所以第二节中提到的四种方法，可以做如下比较，还是那就话：没有最好，只有最合适。 

| 解决方案 | 优点 | 缺点 |
| :--- | :--- | :--- |
| 简单分布式锁\(Tim yang\) |  1. 思路简单2. 保证一致性 | 1. 代码复杂度增大2. 存在死锁的风险3. 存在线程池阻塞的风险 |
| 加另外一个过期时间\(Tim yang\) |  1. 保证一致性 | 同上  |
| 不过期\(本文\) | 1. 异步构建缓存，不会阻塞线程池 | 1. 不保证一致性。2. 代码复杂度增大\(每个value都要维护一个timekey\)。3. 占用一定的内存空间\(每个value都要维护一个timekey\)。 |
| 资源隔离组件hystrix\(本文\) | 1. hystrix技术成熟，有效保证后端。2. hystrix监控强大。   | 1. 部分访问存在降级策略。  |

  
总结

   1.  热点key + 过期时间 + 复杂的构建缓存过程 =&gt; mutex key问题

   2. 构建缓存一个线程做就可以了。

   3. 四种解决方案：没有最佳只有最合适。  


